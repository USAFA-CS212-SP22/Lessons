{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "* Describe when classification is the appropriate analysis technique\n",
    "* Use scikit-learn to perform classification\n",
    "\n",
    "\n",
    "## Iris Species Classification\n",
    "The [Iris flower dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set) is one of the most popular datasets for machine learning. \n",
    "\n",
    "As you know, there are 4 features: sepal length, sepal width, petal length, and petal width. The only difference between this dataset and the one we used in the Clustering Exercise is that now we have the target (alternatively known as class or label). The dataset contains one target: species. We will explore a couple different classification techniques to use our 4 features to predict the target.\n",
    "\n",
    "![iris](images/iris.png)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "Classification is a supervised analytical technique used on labeled categorical data to accurately predict the class of unknown data points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. K-Nearest Neighbors (KNN) Pseudocode\n",
    "1. Pick a value for K.\n",
    "2. Search for the K observations in the training data that are \"nearest\" to the measurements of the unknown iris.\n",
    "3. Use the most popular response value from the K nearest neighbors as the predicted response value for the unknown iris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example training data\n",
    "\n",
    "![Training data](images/knn_dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN classification map (K=1)\n",
    "**Note:** This is NOT k-means clustering and we are NOT splitting our data into K groups. We are looking at the K nearest neighbors (data points) and classifying the new data point as that neighbor's class. For example if we found a new iris that was plotted in the top left corner, based on out K=1 model, we would classify this new point as red.\n",
    "\n",
    "![1NN classification map](images/1nn_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN classification map (K=5)\n",
    "\n",
    "![5NN classification map](images/5nn_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import load_iris function from datasets module\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# save \"bunch\" object containing iris dataset and its attributes\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the Data\n",
    "Now that we have loaded the data, let's get familiar with the dataset and what it looks like. First, examine the type of object for our variable `iris`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what type of object is iris?\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a different object type that we haven't seen before! Let's look into it by typing `iris`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'C:\\\\Users\\\\DFCS-General\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like this `sklearn.utils.Bunch` is simply a dictionary containing the keys `data`, `target`, `frame`, `target_names`, `DESCR` (description), `feature_names` and `filename`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what does the data look like? an array!\n",
    "iris.data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what do the targets look like? another array!\n",
    "iris.target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store feature matrix in \"X\"\n",
    "X = iris.data\n",
    "\n",
    "# store response vector in \"y\"\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of X\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of y\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target names\n",
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature_names\n",
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Four Part scikit-learn Modeling Process\n",
    "Now that we understand our dataset, let's start to explore a four part process to Choose and Train a Model (Steps 3 and 4 in the 7 Machine Learning Steps) \n",
    "**Part 1:** Import the class (model) you plan to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2:** \"Instantiate\" the \"estimator\"\n",
    "\n",
    "- \"Estimator\" is scikit-learn's term for model\n",
    "- \"Instantiate\" means \"make an instance of\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Name of the object does not matter\n",
    "- Can specify tuning parameters (aka \"hyperparameters\") during this step\n",
    "- All parameters not specified are set to their defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=1)\n"
     ]
    }
   ],
   "source": [
    "print(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3:** Fit the model with data (aka \"model training\")\n",
    "\n",
    "- Model is learning the relationship between X and y\n",
    "- Occurs in-place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 4:** Predict the response for a new observation\n",
    "\n",
    "- New observations are called \"out-of-sample\" data\n",
    "- Uses the information it learned during the model training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's assume we see a flower with the measurements 3, 5, 4, and 2\n",
    "knn.predict([[3, 5, 4, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Returns a NumPy array containing predicted labels\n",
    "- Can predict for multiple observations at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = [[3, 5, 4, 2], [5, 4, 3, 2]]\n",
    "knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Different Value for K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 2 - instantiate the model (using the value K=5)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Part 3 - fit the model with the original data\n",
    "knn.fit(X, y)\n",
    "\n",
    "# Part 4 - predict the response for new observations\n",
    "knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logisitic Regression\n",
    "Logistic Regression isn't far from Linear Regression, they are both under the supervised learning umbrella! We are using some features (X) to predict some target (y). The distinct difference is that Classification targets are categorical/discrete where Regression targets are continuous/numerical. \n",
    "\n",
    "Binary Classification (target can only be one of two values, show below) is the simplist form of logistic regression. We are taking it one small step further and we are conducting Multi-Class Classification because we have three different iris species.  \n",
    "![Logistic Regression](images/logreg.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our four part modeling process again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 1 - import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Part 2 - instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression(max_iter=5000)\n",
    "\n",
    "# Part 3 - fit the model with data\n",
    "logreg.fit(X, y)\n",
    "\n",
    "# Part 4 - predict the response values for the observations in X\n",
    "logreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the predicted response values\n",
    "y_pred = logreg.predict(X)\n",
    "\n",
    "# check how many predictions were generated\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Accuracy\n",
    "Classification accuracy is a common evaluation metric for classification problems. It represents the proportion of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "# compute classification accuracy for the logistic regression model\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model above used 100% of the data points to train the model, so it essentially has \"seen all of the answers\". This accuracy is known as **training accuracy** (the accuracy of predicting training data). Examine the classification accuracy for our KNN (K=1) and KNN (K=5) models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN (K=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X, y)\n",
    "m\n",
    "print(metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN (K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X, y)\n",
    "y_pred = knn.predict(X)\n",
    "print(metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with training and testing on the same data\n",
    "\n",
    "- Goal is to estimate likely performance of a model on predicting data that **it has never seen before**.\n",
    "- Maximizing training accuracy rewards **overly complex models** that won't necessarily generalize\n",
    "- Unnecessarily complex models **overfit** the training data (green line)\n",
    "\n",
    "![Overfitting](images/overfitting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Splitting our Data\n",
    "1. Split the dataset into two pieces: a **training set** and a **testing set**.\n",
    "2. Train the model on the **training set**.\n",
    "3. Test the model on the **testing set**, and evaluate how well we did.\n",
    "\n",
    "![Train Test Split](images/train_test_split.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did this accomplish?\n",
    "\n",
    "- Model can be trained and tested on **different data**\n",
    "- Response values are known for the testing set, and thus **predictions can be evaluated**\n",
    "- **Testing accuracy** is a better estimate than training accuracy of out-of-sample performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the shapes of the new X objects\n",
    "X_train.shape\n",
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the shapes of the new y objects\n",
    "y_train.shape\n",
    "# y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model on the training set\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the testing set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# compare actual response values (y_test) with predicted response values (y_pred)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN (K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN (K=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we find an even better value for K?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try K=1 through K=25 and record testing accuracy\n",
    "k_range = list(range(1, 26))\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    scores.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# allow plots to appear within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the relationship between K and testing accuracy\n",
    "sns.lineplot(x=k_range, y=scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Training accuracy** rises as model complexity increases\n",
    "- **Testing accuracy** penalizes models that are too complex (over-fit) or not complex (under-fit) enough\n",
    "- For KNN models, complexity is determined by the **value of K**\n",
    "    - Large value of K = simple model = underfit\n",
    "    - Small vlaue of  K = complex model = overfit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
