{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "* Describe when linear regression is the appropriate analysis technique\n",
    "* Use scikit-learn to perform Linear Regression and Multiple Linear Regression\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Linear Regression\n",
    "[Linear Regression](https://towardsdatascience.com/simple-linear-regression-in-four-lines-of-code-d690fe4dba84) is a supervised analytical technique used on continuous data (both features and targets) to predict a dependent variable. \n",
    "\n",
    "**Q1.1** [Try it out here!](https://www.desmos.com/calculator/jwquvmikhr) I recommend adding another data point (x,y) and see how the equation (slope and intercept) for the line changes. If you add a point below the line, do you expect the slope of the line to decrease or increase? What about above the line? It looks like linear regression is trying to find the best fit line between all of our points!\n",
    "\n",
    "## Simple Linear Regression (one independent variable) Pseudocode\n",
    "Before we get into the explanation of Linear Regression, let's cover our variables and what they represent:\n",
    "* Feature: $x$\n",
    "* Target: $y$\n",
    "* Intercept: $\\beta_{0}$\n",
    "* Slope: $\\beta_{1}$\n",
    "\n",
    "The pseudocode for linear regression isn't very exciting because we can simply calculate the slope and intercept. We will then use the slope and intercept to create the equation for a line: $y$ = $\\beta_{0}$ + $\\beta_{1}$ * $x$\n",
    "\n",
    "<span style= \"font-size:2em;\">**Slope:** $\\beta_{1}$ = $\\frac{\\sum_{i} (x_{i} - \\bar{x})(y_{i} - \\bar{y})}{\\sum_{i} (x_{i} - \\bar{x})^2}$\n",
    "\n",
    "If we rearrange the equation for a line, we can calculate the intercept:\n",
    "\n",
    "<span style= \"font-size:2em;\">**Intercept:** $\\beta_{0}$ = $\\bar{y}$ - $\\beta_{1}$ * $\\bar{x}$\n",
    "\n",
    "The first part of this exercise will walk through the seven Machine Learning Steps to use simple linear regression to predict GPA based on SAT scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# regression module\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 & 1.2 Gather and Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data from `linear_regression.csv` and save it to the variable `data`. Inspect the first five lines of the DataFrame `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by loading the data\n",
    "data = pd.read_csv('linear_regression.csv')\n",
    "\n",
    "# Let's explore the top 5 rows of the df\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Choose a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The single feature (`SAT`) is **continuous** and we have a target (`GPA`), which is also **continuous**, so our best model is a Simple Linear Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Train the Model\n",
    "In this step our goal is to find the slope and intercept for the equation of a line that best fits our data. This equation looks like:\n",
    "\n",
    "<span style= \"font-size:1.5em;\">GPA = $\\beta_{0}$ + $\\beta_{1}$ * SAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare the independent and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a single independent variable: 'SAT'\n",
    "x = data['SAT']\n",
    "\n",
    "# and a single dependent variable: 'GPA'\n",
    "y = data['GPA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Often it is useful to check the shapes of the features\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn is expecting a 2D array (a matrix) for the features (x), so we need to reshape the 1D array into a 2D array. Both of the lines of code below work the same because (just like list indexing) the 84th index is the same as -1st index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_matrix = x.values.reshape(84,1)\n",
    "# x_matrix = x.values.reshape(-1,1)\n",
    "\n",
    "# Check the shape just in case\n",
    "x_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Regression\n",
    "Here is the [Linear Regression documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html), in case you would like to look more into what is going on. Start similarly to kmeans clustering by creating an abstract LinearRegression object and assign it to the variable `reg`. Then fit the model using the independent and dependent variables, `x_matrix` and `y`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a linear regression object\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the regression\n",
    "reg.fit(x_matrix,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-squared\n",
    "One of the simplest and best ways to find the \"goodness\" or \"fit\" (how close our data fit the regression line) of a Linear Regression model is to find the R-squared value. There is not a good value for R-sqared... For some human behavior psychology models, a low R-squared value (< 0.5) might be amazing! Additionally there might be some models with extremely high R-squared values (> 0.95) that are actually poorly fit models. This may seem counterintuitive, but just know that there is an **art** to the **science** of Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find R-squared with score method\n",
    "reg.score(x_matrix,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Tuning\n",
    "The R-squared value is a good indicator of whether or not we need to tune our model, but unfortunately there isn't a whole lot we can *tune* for a simple Linear Regression model. One thing we might consider to tune a Linear Regression model is adding another feature. That is called Multiple Linear Regression and we will do that below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients\n",
    "**Note:** the output is an array, as we may have several coefficients (that would be Multiple Linear Regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coefficient\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intercept\n",
    "**Note:** the result is a float as we expect a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get intercept\n",
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we make any predictions using new data, let's stop to understand what the coefficient and intercept are actually telling us. Remember, linear regression creates a line $y$ = $\\beta_{0}$ + $\\beta_{1}$ * $x$ (`GPA = intercept +  coef * SAT`). So, if a student had a zero on the SAT, we can predict their GPA by using the same equation. `GPA = 0.275 + 0.0017 * 0`, which is a GPA of 0.275. **For every SAT point a student earns, we predict their GPA to rise 0.0017 points.**\n",
    "\n",
    "We can use the `predict` method to predict new GPA values based on provided SAT scores. **Note:** the result is an array, as we can predict more than one value at a time depending on how many values we input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict GPA for 1740 SAT score\n",
    "reg.predict([[1740]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create a DataFrame with several different values of SAT\n",
    "new_data = pd.DataFrame(data=[1740,1760],columns=['SAT'])\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict GPA for SAT scores in DataFrame\n",
    "reg.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# store the predictions in a new series in the same DataFrame\n",
    "new_data['Predicted_GPA'] = reg.predict(new_data)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Regression Line Using Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "plt.scatter(x,y)\n",
    "\n",
    "# using the parameters from the model to create the regression line (y = b0 + b1*x)\n",
    "yhat = reg.coef_ * x_matrix + reg.intercept_\n",
    "\n",
    "# plotting regression line\n",
    "fig = plt.plot(x,yhat, lw=4, c='orange', label='regression line')\n",
    "\n",
    "# labelling axes\n",
    "plt.xlabel('SAT', fontsize = 20)\n",
    "plt.ylabel('GPA', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the scatter plot above, we can see that our predicted linear equation (orange line) fits the data (blue dots) pretty well! **Fun insight to scikit-learn's magic: This line was created by trying a bunch of different lines and minimizing the distance from the line to all the points.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Regression Line Using Seaborn\n",
    "We can easily use Seaborn to plot the regression line too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "sns.regplot(x = x,y = y)\n",
    "\n",
    "# Labelling our axes\n",
    "plt.xlabel('SAT', fontsize = 20)\n",
    "plt.ylabel('GPA', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Multiple Linear Regression\n",
    "Multiple Linear Regression is **very** similar to Simple Linear Regression, the only difference is that we are now using multiple features to predict our target. During Simple Linear Regression we tried to find a line that fit our 2D scatter plot the best. Now, with Multiple Linear Regression, we will be creating the same model in multi-dimension space. The plot below is using the features `TV` and `Radio` to predict sales. Notice the model is creating the best fit plane (3D) instead of a line (2D).\n",
    "\n",
    "![multiplereg](multiple.png)\n",
    "\n",
    "Unfortunately, we can only visualize this in 2 and 3 dimensions, so we won't be able to plot when we have more than two features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 & 2.2 Gather and Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data from `multiple_linear_regression.csv` and save it to the variable `data`. Inspect the first five lines of the DataFrame `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by loading the data\n",
    "data = pd.read_csv('multiple_linear_regression.csv')\n",
    "\n",
    "# Let's explore the top 5 rows of the df\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Choose a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both features (`SAT` and `ACT`) are **continuous** and we have a target (`GPA`), which is also **continuous**, so we can either use a Simple Linear Regression model with one of our features or we can use a Multiple Linear Regression model which uses multiple features. Let's try out a Multiple Linear Regression model to see if adding in the `ACT` feature improves the fit of our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Train the Model\n",
    "In this step our goal is to find the slope and intercept for the equation of a line that best fits our data. This equation looks like:\n",
    "\n",
    "<span style= \"font-size:1.5em;\">GPA = $\\beta_{0}$ + $\\beta_{1}$ * SAT + $\\beta_{2}$ * ACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are now 2 independent variables: 'SAT' and 'ACT'\n",
    "x = data[['SAT', 'ACT']]\n",
    "\n",
    "# and a single depended variable: 'GPA'\n",
    "y = data['GPA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start the same by creating a linear regression object\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Fit the regression\n",
    "reg.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r-squared\n",
    "reg.score(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Tuning\n",
    "One of the best ways to tune a Multiple Linear Regression model is adding and removes features. It doesn't appear that adding the variable helped us too much, so I would consider removing this variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the coefficients\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the intercept\n",
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict GPA for SAT = 1740, ACT = 32\n",
    "reg.predict([[1740, 32]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a DataFrame with several different values of SAT and ACT\n",
    "new_data = pd.DataFrame(data=[[1740, 32],[1760, 35]],columns=['SAT', 'ACT'])\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict GPA from new_data\n",
    "reg.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# store the predictions in a new series in the same DataFrame\n",
    "new_data['Predicted_GPA'] = reg.predict(new_data)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection = '3d')\n",
    "\n",
    "x1 = data['SAT']\n",
    "x2 = data['ACT']\n",
    "y = data['GPA']\n",
    "\n",
    "ax.set_xlabel(\"SAT\")\n",
    "ax.set_ylabel(\"ACT\")\n",
    "ax.set_zlabel(\"GPA\")\n",
    "\n",
    "ax.scatter(x1, x2, y, color='k', zorder=15, marker='o', alpha=0.5)\n",
    "\n",
    "# Using the parameters from the model to create the regression plane (y = b0 + b1x1 + b2x2)\n",
    "yhat = reg.intercept_ + reg.coef_[0] * x1 + reg.coef_[1] * x2\n",
    "\n",
    "# create ranges of SAT and ACT values to predict (corners of the plane)\n",
    "x1_pred = np.linspace(min(x1), max(x1), 50)   # range of porosity values\n",
    "x2_pred = np.linspace(min(x2), max(x2), 50)  # range of brittleness values\n",
    "xx1_pred, xx2_pred = np.meshgrid(x1_pred, x2_pred)\n",
    "model_viz = np.array([xx1_pred.flatten(), xx2_pred.flatten()]).T\n",
    "\n",
    "# predict GPA based on the plane of SAT and ACT values\n",
    "predicted = reg.predict(model_viz)\n",
    "\n",
    "# draw the plane\n",
    "ax.scatter(xx1_pred.flatten(), xx2_pred.flatten(), predicted, facecolor=(0,0,0,0), s=20, edgecolor='#70b3f0')\n",
    "\n",
    "# change the view angle of the plot\n",
    "ax.view_init(elev=4, azim=114)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
